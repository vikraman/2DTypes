\section{The groupoid of finite types}~\label{sec:finite}

In this section, we describe \review{the algebraic structure} of the groupoid of
finite types, and give \review{a computable presentation} for it.

\vc{The groupoid of finite types is the free symmetric monoidal groupoid on one
  generator. This can be presented as an algebraic 2-theory, which is our syntax
  for $\PiHatLang$. Vertical categorification of natural numbers as a free
  commutative monoid. See groupoidification.}

\todo{Check Brent Yorgey's thesis?}

In the previous~\cref{sec:univalent}, we established that paths in $\UFin$ are equivalent to families of automorphisms
of $\Fin{n}$ for every $n:\Nat$, that is, bijections on finite sets of size $n$. This is the extensional view of
permutations. In the following sections, we will characterise these permutations syntactically- specifically, using a concept of \textit{a presentation} from the group theory.

\todo{Move.}

Although the meaning of a permutation - that is, the specific bijective function that it represents - is in some sense all there is, manipulating them syntactically still has its advantages. By writing reversible programs, we think of them in an intensional way. Comparing two programs for equality by evaluating them on all points in the domain is a very crude - and maybe even inefficient - way of doing that.

It is crude, because there is no way of enforcing additional constraints on the process of transforming one program into another, and no way of inspecting what transformation occured. We can imagine a practical situation in which reversible circuts admit one kind of optimization \jk{FPGA?}, but do not admit another, even though they are equivalent in the extensional sense - or maybe one of these transformations is cheaper than another, or maybe it is important to know which transformation did occur for the \jk{producer(?)} to focus their resources of improving this kind of transformations. By comparing the circuits extensionally, the proof object = the path from one into the other - does not have any structure,  it is just a check that the values match.

On the other hand, even though in general, the equality of circuits requires exponential time jk{triple check}, the proof object can be still very small. This creates structure that can possibly be exploited in a heurisic way. \jk{Additionally, if the goal is to convince third-party that two circuits are the same, we can just present the proof instead of showing the equality directly - for example, by choosing a particularly short one}.

Taking all this into account, it is clear that we must seek a syntactic way of computing the meaning of the circuit, instead of just directly evaluating it to $\Aut[\Fin[n]]$ - since when we go back and quote the permutation as a circuit (in a normal form), there was no "trace" left to see what transformation (what sequence of 2-paths) maps the old one into the new one.

Fortunately, group theory already has language in which such problems are expressed - we will be looking at solving the \textit{word problem}. Because $\PiLang$ is used for reasoning about reversible functions on finite sets, the group that we are interested in is the group of permutations on a finite set, which is classically known as the symmetric group,
$\Sn$. Putting it in this form allows us to connect to the broader scope of computational group theory and reuse ideas from there. For example, during the proof, we will use \emph{Lehmer codes} (introduced in \cref{subsec:lehmer}) - a concept used widely in this context, which makes for a very convenient and compact method of representing permutations on a computer.

The goal of this section is to reconcile two different approaches to defining the symmetric group. We already defined
$\UFin$ in the previous section, and showed how its loopspace encodes the automorphism group. Now, we're going to define
the same group in a different way, in terms of the symmetric group presented using generators and relations, and show
how the two points of view are equivalent.

\todo{Big example: Start from a listed permutation, show Lehmer code, then adjacent swaps.}
\todo{Justification for why we need group theory.}

\subsection{Groups}

From universal algebra, a group is simply a set with a 0-ary constant (the neutral element), a binary operation for group multiplication, and a unary inverse operation. The neutral element has
to satisfy unit and inverse laws, and the multiplication has to be associative.

A very simple example of a group is $\mathbb{Z}$, where the neutral element is 0, the inverse of $k$ is $-k$, and the group multiplication is given by integer addition.

In type theory, a group $G$ can be defined as an $\hSet$ $S$ with the following pieces of data:

\begin{enumerate}
  \item a unit or neutral element $e : S$
  \item a multiplication function $m : S \times S \to S$ written as $(g_{1}, g_{2}) \mapsto g_{1} \mult g_{2}$, that satisfies
        \begin{enumerate}
          \item the unit laws, for all $g : S$, that \( g \mult e \id g \) and \( e \mult g \id g \)
          \item the associativity law, for all $g_{1}, g_{2}, g_{3} : S$, that \( g_{1} \mult (g_{2} \mult g_{3}) \id (g_{1} \mult g_{2}) \mult g_{3} \)
        \end{enumerate}
  \item an inversion function $i : S \to S$ written as $g \mapsto \inv{g}$, that satisfies
        \begin{enumerate}
          \item the inverse laws, for all $g : S$, that \( g \mult \inv{g} \id e \) and \( \inv{g} \mult g \id e \)
        \end{enumerate}
\end{enumerate}

However, more conveniently, in HoTT, we can instead use groupoids to talk about groups internally. A group can be
identified with a 1-object groupoid, using a technique called delooping. The delooping of a group $G$ is a groupoid
$\B{G}$ given by a unique object $\pt$ with self-loops that are 1-paths $\pt \id_{\B{G}} \pt$ corresponding to the
elements of $G$. Note that the group operations are automatically given by operations on the identity type, with
$\refl_{\pt}$ for the neutral element, path composition for the group multiplication, and path inverse for the group
inverse. These satisfy the group laws as well, up to the identity type, using the groupoid coherence laws. Moreover, for
1-groups which are supposed to be sets, these 2-paths should be propositions, so we have to restrict $\B{G}$ to be a
1-groupoid. Hence, a group is simply given by a pointed, connected
1-type~\cite*{buchholtzHigherGroupsHomotopy2018,symmetryBook2021}.

For example, given a pointed type $(A:\UU, a:A)$, the automorphism group structure at $a$ is given by $a \id_{A} a$. Of
course, for 1-groups we will require that $a \id_{A} a$ is an $\hSet$, which is enforced by having $A$ be a groupoid. In
our running example for the permutation group on finite sets, we have that $\Fin[n]$ is an $\hSet$, and hence,
$\UFin[n] \defeq \BAut[\Fin[n]]$ is a pointed, connected 1-type, whose loopspace $\loopspace[\BAut[\Fin[n]],F_{n}]$ is
equivalent to $\Aut[\Fin[n]] \defeq (\Fin[n] \eqv \Fin[n]) \eqv (\Fin[n] \id_{\UU} \Fin[n])$, which has the
corresponding automorphism group structure.

\subsection{Free groups}

Usually, there are are many equations, besides the group axioms, that hold for the elements of a group. For example, in
the group $\mathbb{Z}/3\mathbb{Z}$, where group multiplication is given by addition modulo 3, we have an equation
$1 + 1 + 1 = 0$, which is not a consequence of group axioms, but is specific to the particular group
$\mathbb{Z}/3\mathbb{Z}$. A free group has the property that no other equations except the ones directly implied by the
group axioms, such as $g \mult \inv{g} = e$, hold. Thus, $\mathbb{Z}/3\mathbb{Z}$ is not a free group. To be able to
give an equational presentation of a group, we start by constructing the free group, then show how to add new equations
to it.

Given any set $A$, we can describe the free group $F(A)$ on $A$. We draw the elements from the alphabet $A$, close them
under the group operations of multiplication and inverse, and identify them by the group axioms. For example, the
singleton set generates the additive group of integers $\mathbb{Z}$ we introduced before. In this context, we will call
$A$ the generating set of $F(A)$. Working in HoTT, as before, we can simply use higher inductive types to define the
free group, by adding path constructors for the axioms we want.

\todo{Better notation for HITs?}
\begin{definition}
  Given an $\hSet$ $A$, the free group $F(A)$ on it is given by a higher
  inductive type with the following point and path constructors. Notice the
  similarity with the definition of a group structure in~\ref{subsec:groups},
  but note that each operation here is a generator for the type $F(A)$\dots.
  \begin{itemize}
    \item An inclusion function $\eta_{A} : A \to F(A)$
    \item A multiplication function $m : F(A) \times F(A) \to F(A)$
    \item An element $e : F(A)$
    \item An inverse function $i : F(A) \to F(A)$
  \end{itemize}
  \smallskip
  \begin{itemize}
    \item For every $x, y, z : F(A)$, a path $\term{assoc} : m(x, m(y, z)) \id m(m(x, y), z)$
    \item For every $x : F(A)$, paths $\term{unitr} : m(x, e) \id x$ and $\term{unitl} : m(e, x) \id x$
    \item For every $x : F(A)$, paths $\term{invr} : m(x, i(x)) \id e$ and $\term{invl} : m(i(x), x) \id e$
    \item A 0-truncation, for every $x, y : F(A)$ and $p, q : x \id y$, a 2-path $\term{trunc} : p \id q$
  \end{itemize}
\end{definition}

A group homomorphism between groups is a function between the underlying sets that preserves the group structure, which
we write as $G_1 \to^G G_2$. Using the induction principle for $F(A)$, we can easily prove the universal property of
free groups, stemming from the free-forgetful adjucntion between the category of groups and sets. Informally, the
universal property states that if we know how a map $f$ acts on the generating set $A$, we know exactly how it acts on
every element of the group $F(A)$.

\begin{proposition}[Universal Property of $F(A)$]~\label{prop:free-groups}
  Given a group $G$ and a map $f : A \to G$, there is a unique group
  homomorphism $\extend{f} : F(A) \to^G G$ such that $\extend{f} \comp \eta_A
    \htpy f$. Equivalently, composition with $\eta_A$ gives an equivalence $F(A)
    \to^G G \eqv A \to G$. Alternatively, the type of group homomorphisms $h :
    F(A) \to^G G$ satisfying $h \comp \eta_A \htpy f$ is contractible.

  % https://q.uiver.app/?q=WzAsMyxbMCwyLCJBIl0sWzAsMCwiRihBKSJdLFsyLDAsIkciXSxbMCwxLCJcXGV0YV9BIl0sWzAsMiwiZiIsMl0sWzEsMiwiXFxleHRlbmR7Zn0iLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XSxbMyw0LCJcXGlkIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfSwic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoibm9uZSJ9LCJoZWFkIjp7Im5hbWUiOiJub25lIn19fV1d
  \[\begin{tikzcd}
      {F(A)} && G \\
      \\
      A
      \arrow[""{name=0, anchor=center, inner sep=0}, "{\eta_A}", from=3-1, to=1-1]
      \arrow[""{name=1, anchor=center, inner sep=0}, "f"', from=3-1, to=1-3]
      \arrow["{\extend{f}}", dashed, from=1-1, to=1-3]
      \arrow["\id", Rightarrow, draw=none, from=0, to=1]
    \end{tikzcd}\]
\end{proposition}

Although this definition is close to the intuitive universal-algebraic definition, it is not the most convenient one to
work with. Besides being interested in the elements of the group, we also want to characterise the path space of the
group. This HIT definition of $F(A)$ has lots of path constructors corresponding to each group axiom, making it
difficult to describe its path space.

Instead, we will think about elements of the free group as words over an alphabet of letters drawn from the generating
set \emph{and} the set of their formal inverses. If we take the disjoint union of $A$ with itself, that is, $A + A$ as
the group's underlying set, we can use $\inl/\inr$ to mark the elements -- $\inl{a}$ means $a$ and $\inr{a}$ means
$\inv{a}$. Hence, we can encode the free group using the free monoid, that is, lists of $A + A$. Additionally, we need
to ensure that group laws hold, so words identified by the group equations are equal. Thus, elements of the free group
will actually be equivalence classes of lists on $A + A$.

\begin{definition}~\label{def:presentation}
  Let $A$ be an $\hSet$, and $\List[\blank]$ the free monoid. The free group
  $F(A)$ on $A$ is the set-quotient of $\List[A + A]$ by the congruence closure
  of the relation $a \cons \inv{a} \cons \nil \sim \nil$.
\end{definition}

\begin{proposition}
  $F(A) \defeq \quot{\List[A + A]}{\sim^{\ast}}$ has a group structure, with the empty list $\nil$ for the neutral
  element, multiplication given by list append $\append$, and inverse given by flipping $\inl$ and $\inr$, followed by
  reversing the list. Further, $F(A)$ with $\eta_A : A \to F(A) \defeq \inl(a) \cons \nil$ satisfies the universal
  property of free groups, as stated in~\cref{prop:free-groups}.
\end{proposition}

\subsection{Group presentations}

\review{We have already seen many examples of groups, that is, sets carrying a group structure, but now we'll see how to
  syntactically represent them -- which is the role of group presentations.}

A presentation of a group builds it by starting from the free group $F(A)$ and introducing a collection of equations
that have to be satisfied in the resulting group. For example, if we take $F(\unit) \defeq \mathbb{Z}$ and add an
equation $1 + 1 + 1 = 0$, the resulting group would be $\mathbb{Z}/3\mathbb{Z}$. Note that not all groups have finite
(or computable) presentations, and, a group can have any number of presentations.

\begin{definition}
  Let $A$ be an $\hSet$ and $R : (A + A) \to (A + A) \to \UU$ a binary relation on $A + A$. The group
  $F(\langle A ; R \rangle)$ presented by $A$ and $R$, is given by the set-quotient of the free group $F(A)$ by the
  closure of $R$, or equivalently, as the coequaliser
  \[\begin{tikzcd}
      FR && FA && F(\langle A ; R \rangle)
      \arrow[shift right=2, from=1-1, to=1-3]
      \arrow[shift left=2, from=1-1, to=1-3]
      \arrow[two heads, from=1-3, to=1-5]
    \end{tikzcd}\]
\end{definition}

The universal property of the above definition allows for properly extending the relation on the generating set to the
whole group.\vc{check!}

\begin{proposition}[Universal property of $F(\langle A ; R \rangle)$]
  Given a group $G$ and a map $f : A \to G$ that respects $R$, there is a unique group homomorphism
  $\extend{f} : F(\langle A ; R \rangle) \to^G G$ such that $\extend{f} \comp \eta_A \htpy f$.
\end{proposition}

To relate this to our original problem, the generators of the group can be thought of as the primitive combinators in a
(reversible) programming language, the group structure gives the composition and inversion operations, and the relations
describe how these primitive operations interact with each other.

As we mentioned, instead of operating directly with a particular group, we focus on the syntactic presentation. While
before, the only way to decide the equality of two elements in the group was to compute and check them on the nose, now
it is reduced to a \emph{word problem}, that is, deciding whether one word -- a representative of the group elements'
equivalence class, can be reduced to another word, using the group's relations. This can be thought of as a rewriting
system. However, these equations are not directed, so it is not always possible to construct a well-behaved rewriting
system. In general, the word problem for groups is proven to be undecidable.

\jk{Example?}
\todo{Examples: empty relation, full relation, van Kampen of $\pi_{1}$}

\subsection{Presenting the permutation group}

We have already seen that the group of permutations, or the symmetric group $\Sn$, can be defined by taking the type
$\Aut[\Fin[n]]$ as the underlying set, and showing that it has the appropriate group structure. Now we're going to give
a presentation for it, by defining a set of generators and relations.

There is an element of choice here -- as we already mentioned, a group can be presented in many different ways. For
example, we could generate the permutation group on $\Fin[n]$ by using generators that:

\begin{itemize}
  \item swap the $i$-the element with the $(i+1)$-th element, that is, adjacent swaps, or
  \item swap the $i$-th element with the $j$-th element, for arbitrary $i$-s and $j$-s, or
  \item swap the $i$-th element with an element at a fixed position, or
  \item flip a prefix $\Fin[k]$ of $\Fin[n]$ for $k \leq n$, or
  \item cyclically shift any subset of $\Fin[n]$.
\end{itemize}

One way of thinking about these presentations is via sorting algorithms, which use different primitive operations. A
sorting algorithm has to calculate a permutation of a list or a finite set, which satisfies the invariant of being a
sorted sequence, which means, the primitive operations of a sorting algorithm are able to generate all the permutations
on a given list. So, a chosen set of reversible operations in a sorting algorithm can be a good candidate for the
generators of a permutation group.

For example, bubble sort uses the primitive operation of adjacent swaps, insertion sort and selection sort use the
primitive operation of swapping the $i$-th element with the $j$-th element, cycle sort uses cyclical shifts of
subsequences, pancake sort uses flips of prefixes of the list, et cetera~\todo{check!}. The choice of generators for our
presentation is important for the following reasons.

\begin{itemize}
  \item It affects the difficulty of solving the word problem in $\Sn$ and formalising the proof of its correctness. In
        the following subsections, we build a rewriting system using the generators and relations, and we need to prove
        and formalise strong normalisation for this system.
  \item The choice of generators dictates which words become normal forms in this presentation of $\Sn$. These normal
        forms dictate the shape of the synthesised and normalised boolean circuits, which is the application we have in
        mind.
  \item Finally, the generators have to closely match the $\PiLang$ combinators so that we can quote back a permutation
        to a $\PiLang$ program, for the proof of completeness.
\end{itemize}

We use a presentation based on adjacent transpositions for generators, called a~\emph{Coxeter presentation}, which we
also use to solve the word problem for $\Sn$. Connecting it back to the language $\PiLang$, we will show that it is
possible to encode all $\PiLang$ combinators using adjacent transpositions (in~\cref{sec:equivalence}).

\subsubsection{Coxeter Presentation}

The primitive operations we use are going to be adjacent swaps. When dealing with permutations on an $n + 1$-element
set, there are $n$ adjacent transpositions, transposition number $k$ swapping elements $\el{k}$ and $\el{k+1}$. Thus,
the generating set would be $\Fin[n]$. There are three relations that we're going to specify for this presentation --
these are the laws that these generators should satisfy. It is easiest to visualise them as braid diagrams.

First, swapping the same two elements two times in a row should be the same as doing nothing:

\[
  \begin{tabular}{m{0.3\linewidth}m{0.1\linewidth}m{0.3\linewidth}}
    \begin{center}
      \begin{tikzpicture}
        \pic[local bounding box=my braid,braid/.cd,
          number of strands = 2,
          thick]
        {braid={ s_1, s_1}};
      \end{tikzpicture}
    \end{center}
     &
    \(\xlongrightarrow[]{\cancel}\)
     &
    \begin{center}
      \begin{tikzpicture}
        \pic[local bounding box=my braid,braid/.cd,
          number of strands = 2,
          thick]
        {braid={1, 1}};
      \end{tikzpicture}
    \end{center}
  \end{tabular}
\]

Second, when swapping two distinct pairs of elements (i.e. when the indices of two transpositions differ by at least 1),
it should not matter in which order the swapping happens, that is, we can slide the wires freely.

\[
  \begin{tabular}{m{0.3\linewidth}m{0.1\linewidth}m{0.3\linewidth}}
    \begin{center}
      \begin{tabular}{m{0.3\linewidth}m{0.1\linewidth}m{0.3\linewidth}}
        \begin{tikzpicture}
          \pic[local bounding box=my braid,braid/.cd,
            number of strands = 2,
            thick]
          {braid={ 1, s_1}};
        \end{tikzpicture}
         &
        \(\cdots\)
         &
        \begin{tikzpicture}
          \pic[local bounding box=my braid,braid/.cd,
            number of strands = 2,
            thick]
          {braid={ s_1, 1 }};
        \end{tikzpicture}
      \end{tabular}
    \end{center}
     &
    \(\xlongrightarrow[]{\swap}\)
     &
    \begin{center}
      \begin{tabular}{m{0.3\linewidth}m{0.1\linewidth}m{0.3\linewidth}}
        \begin{tikzpicture}
          \pic[local bounding box=my braid,braid/.cd,
            number of strands = 2,
            thick]
          {braid={ s_1, 1}};
        \end{tikzpicture}
         &
        \(\cdots\)
         &
        \begin{tikzpicture}
          \pic[local bounding box=my braid,braid/.cd,
            number of strands = 2,
            thick]
          {braid={ 1, s_1}};
        \end{tikzpicture}
      \end{tabular}
    \end{center}
  \end{tabular}
\]

The previous two cases were for the transpositions that either completely overlap, or not overlap at all. The third case
says what happens if we perform transpositions that move the same elements. If the next transposition in the sequence is
equal to the the first one, we endorce a third law -- the braiding relation.

\[
  \begin{tabular}{m{0.3\linewidth}m{0.1\linewidth}m{0.3\linewidth}}
    \begin{center}
      \begin{tikzpicture}
        \pic[local bounding box=my braid,braid/.cd,
          number of strands = 3,
          thick]
        {braid={ s_2, s_1, s_2}};
      \end{tikzpicture}
    \end{center}
     &
    \(\xlongrightarrow[]{\braid}\)
     &
    \begin{center}
      \begin{tikzpicture}
        \pic[local bounding box=my braid,braid/.cd,
          number of strands = 3,
          thick]
        {braid={ s_1, s_2, s_1}};
      \end{tikzpicture}
    \end{center}
  \end{tabular}
\]

\todo{an example/motivation from book.pdf}

This construction is called a Coxeter presentation. Writing it formally, we take the generating set to be $\Fin[n]$,
where the element $k$ corresponds to an adjacent transpositions $\tau_k$, which swaps elements $\el{k}$ and $\el{k+1}$.
Then, we define a binary relation $\cox$ on $\List[\Fin[n]]$, which encodes the laws discussed above.

\begin{definition}[$\cox$]
  \begin{align*}
    \cancel
     & : \forall n \to (n \cons n \cons \nil) \cox \nil                                                     \\
    \swap
     & : \forall k, n \to (\suc[k] < n) \to (n \cons k \cons \nil) \cox (k \cons n \cons \nil)              \\
    \braid
     & : \forall n \to (\suc[n] \cons n \cons \suc[n] \cons \nil) \cox (n \cons \suc[n] \cons n \cons \nil) \\
  \end{align*}
\end{definition}

We define $\cox*$ as the congruence closure of $\cox$.

\begin{definition}[$\cox*$]
  \begin{align*}
    \reflr{\cox}
     & : \forall w \to w \cox* w                                                                                                           \\
    \symr{\cox}
     & : \forall w_{1}, w_{2} \to w_{1} \cox* w_{2} \to w_{2} \cox* w_{1}                                                                  \\
    \transr{\cox}
     & : \forall w_{1}, w_{2}, w_{3} \to  w_{1} \cox* w_{2} \to w_{2} \cox* w_{3} \to w_{1} \cox* w_{3}                                    \\
    \congrf{\cox}{\append}
     & : \forall w_{1}, w_{2}, w_{3}, w_{4} \to  w_{1} \cox* w_{2} \to w_{3} \cox* w_{4} \to w_{1} \append w_{3} \cox* w_{2} \append w_{4} \\
    \relr{\cox}
     & : \forall w_{1}, w_{2} \to w_{1} \cox w_{2} \to w_{1} \cox* w_{2}                                                                   \\
  \end{align*}
\end{definition}

To solve the word problem for $\Sn$, we turn the relations into a rewriting system $(\List[\Fin[n]],\cox*)$. A normal
form of an element can then be computed by following the rewrite rules, and two words can be compared for
$\cox*$-equality by comparing their normal forms. A well-behaved rewriting system has to be strongly normalising and
confluent. First, we observe that after throwing out reflexivity and symmetry, the right hand sides of the relations
$\cox*$ are strictly smaller than the left hand sides, in terms of the lexicographical ordering on words in $\Fin[n]$.
Thus, by directing the relation from left to right, we would get the termination property out of the box.

The system also has to be confluent, meaning that all critical pairs, that is, terms with overlapping possible reduction
rules, have to converge. For example, the pairs below converge.

\[
  \begin{array}{lcr}
    \gspan[\braid][\braid]{\tau_2\tau_1\tau_2\tau_1\tau_2}{\tau_1\tau_2\tau_1\tau_1\tau_2}{\tau_2\tau_1\tau_1\tau_2\tau_1}
     &
    \text{or}
     &
    \gspan[\braid][\cancel]{\tau_2\tau_1\tau_2\tau_2}{\tau_1\tau_2\tau_1\tau_2}{\tau_2\tau_1}
  \end{array}
\]

\begin{proof}
  \[
    \begin{array}{lr}
      % https://q.uiver.app/?q=WzAsNixbMiwwLCJcXHRhdV8yXFx0YXVfMVxcdGF1XzJcXHRhdV8xXFx0YXVfMiJdLFswLDEsIlxcdGF1XzFcXHRhdV8yXFx0YXVfMVxcdGF1XzFcXHRhdV8yIl0sWzQsMSwiXFx0YXVfMlxcdGF1XzFcXHRhdV8xXFx0YXVfMlxcdGF1XzEiXSxbMCwyLCJcXHRhdV8xXFx0YXVfMlxcdGF1XzIiXSxbMiwzLCJcXHRhdV8xIl0sWzQsMiwiXFx0YXVfMlxcdGF1XzJcXHRhdV8xIl0sWzAsMSwiYnJhaWQiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJzcXVpZ2dseSJ9fX1dLFswLDIsImJyYWlkIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoic3F1aWdnbHkifX19XSxbMSwzLCJjYW5jZWwiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJzcXVpZ2dseSJ9fX1dLFszLDQsImNhbmNlbCIsMix7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6InNxdWlnZ2x5In19fV0sWzIsNSwiY2FuY2VsIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoic3F1aWdnbHkifX19XSxbNSw0LCJjYW5jZWwiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJzcXVpZ2dseSJ9fX1dXQ==
      \begin{tikzcd}
        && {\tau_2\tau_1\tau_2\tau_1\tau_2} \\
        {\tau_1\tau_2\tau_1\tau_1\tau_2} &&&& {\tau_2\tau_1\tau_1\tau_2\tau_1} \\
        {\tau_1\tau_2\tau_2} &&&& {\tau_2\tau_2\tau_1} \\
        && {\tau_1}
        \arrow["braid"', squiggly, from=1-3, to=2-1]
        \arrow["braid", squiggly, from=1-3, to=2-5]
        \arrow["cancel"', squiggly, from=2-1, to=3-1]
        \arrow["cancel"', squiggly, from=3-1, to=4-3]
        \arrow["cancel", squiggly, from=2-5, to=3-5]
        \arrow["cancel", squiggly, from=3-5, to=4-3]
      \end{tikzcd}
       &
      % https://q.uiver.app/?q=WzAsNSxbMiwwLCJcXHRhdV8yXFx0YXVfMVxcdGF1XzJcXHRhdV8yIl0sWzAsMSwiXFx0YXVfMVxcdGF1XzJcXHRhdV8xXFx0YXVfMiJdLFsyLDQsIlxcdGF1XzJcXHRhdV8xIl0sWzAsMiwiXFx0YXVfMVxcdGF1XzJcXHRhdV8xXFx0YXVfMiJdLFsxLDMsIlxcdGF1XzFcXHRhdV8xXFx0YXVfMlxcdGF1XzEiXSxbMCwxLCJicmFpZCIsMix7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6InNxdWlnZ2x5In19fV0sWzAsMiwiY2FuY2VsIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoic3F1aWdnbHkifX19XSxbMSwzLCJicmFpZCIsMix7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6InNxdWlnZ2x5In19fV0sWzMsNCwiYnJhaWQiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJzcXVpZ2dseSJ9fX1dLFs0LDIsImNhbmNlbCIsMix7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6InNxdWlnZ2x5In19fV1d
      \begin{tikzcd}
        && {\tau_2\tau_1\tau_2\tau_2} \\
        {\tau_1\tau_2\tau_1\tau_2} \\
        {\tau_1\tau_2\tau_1\tau_2} \\
        & {\tau_1\tau_1\tau_2\tau_1} \\
        && {\tau_2\tau_1}
        \arrow["braid"', squiggly, from=1-3, to=2-1]
        \arrow["cancel", squiggly, from=1-3, to=5-3]
        \arrow["braid"', squiggly, from=2-1, to=3-1]
        \arrow["braid"', squiggly, from=3-1, to=4-2]
        \arrow["cancel"', squiggly, from=4-2, to=5-3]
      \end{tikzcd}
    \end{array}
  \]
\end{proof}

Unfortunately, in the system we defined, this is not true for all critical pairs. One example is the following, where
both endpoints are normal with respect to $\cox*$ relation.

\[
  \gspan[\braid][\swap]{\tau_3\tau_2\tau_3\tau_1}{\tau_2\tau_3\tau_2\tau_1}{\tau_3\tau_2\tau_1\tau_3}
\]

\subsection{Rewriting via Coxeter}

Because of the counter-example discussed, the relations have to be changed. In this section, we will formally define a
rewriting system partially based on the Coxeter relations, and prove that it has the desired properties of confluence
and strong normalisation.

The Coxeter relations are a standard notion in the theory of group presentation~\todo{citation} -- even though we change
the relations a bit, we will not lose the connection. In fact, we will prove that the new relations are equivalent, in a
technical sense, to the standard Coxeter relations $\cox*$.

The new reduction system $(\List[\Fin[n]], \longcox*)$ has generators corresponding to $\swap$, $\cancel$ and $\braid$.
We fix the problem of the non-converging critical pairs discussed previously by changing $\braid$ to be a slightly more
general relation $\longbraid$. \review{Further, we also inline the congruence closure in $\longcox$, allowing arbitrary
  reductions inside the list.}

\todo{but computation is usually done by using Coxeter matrices~\cite{davisGeometryTopologyCoxeter2008}.}

First, we need to define a helper function $n \downf k$.

\begin{definition}[$\downf : (n : \Nat) \to (k : \Nat) \to {\List[\Fin[k + n]]}$]
  \begin{align*}
    n \downf \zero   & \defeq \nil                       \\
    n \downf \suc[k] & \defeq (k + n) \cons (n \downf k)
  \end{align*}
\end{definition}

The result of this function is the sequence \([k + n - 1, k + n - 2, k + n - 3, \ldots, n]\). Since we think of the
number $m$ as the transposition $\tau_m$ which swaps elements $\el{m}$ and $\el{m+1}$, the role of this helper function
is to produce a sequence of transpositions -- a permutation -- which moves element $\el{k + n}$ $k$ places left,
shifting all the elements in between one place right. Expressed in terms of the braiding diagram, for $n = 0$ and $k =
  4$, it has the following form:

\[
  \begin{tikzpicture}
    \pic[local bounding box=my braid,braid/.cd,
      number of strands = 5,
      thick]
    {braid={s_4, s_3, s_2, s_1}};
  \end{tikzpicture}
\]

Then, the directed relation $\longcox$ is defined with the following generators.

\begin{definition}[$\longcox$]
  \begin{align*}
    \longcancel
     & : \forall n, l, r \to (l \append n \cons n \cons r) \longcox (l \append r)                                                                   \\
    \longswap
     & : \forall k, n, l, r \to (\suc[k] < n) \to (l \append n \cons k \cons r) \longcox (l \append k \cons n \append r)                            \\
    \longbraid
     & : \forall n, l, r \to (l \append (n \downf 2 + k) \append (1 + k + n) \cons r) \longcox (l \append (k + n) \cons (n \downf 2 + k) \append r) \\
  \end{align*}
\end{definition}

Constructors $\longcancel$ and $\longswap$ correspond directly to the appropriate constructors of $\cox$ and can be
visualised in the same way as before. The remaining constructor uses the helper function to exchange the order of a long
sequence of transpositions and a single transposition afterwards. For example, for $n = 2$ and $k = 3$, it allows for
the reduction $[6, 5, 4, 3, 2, 6] \longcox* [5, 6, 5, 4, 3, 2]$. Visualised on the braid diagram, it looks as follows:

\[
  \begin{tabular}{m{0.4\linewidth}m{0.1\linewidth}m{0.4\linewidth}}
    \begin{center}
      \begin{tikzpicture}
        \pic[local bounding box=my braid,braid/.cd,
          number of strands = 6,
          thick]
        {braid={s_5, s_4, s_3, s_2, s_1, s_5}};
      \end{tikzpicture}
    \end{center}
     &
    \(\xlongrightarrow[]{\longbraid}\)
     &
    \begin{center}
      \begin{tikzpicture}
        \pic[local bounding box=my braid,braid/.cd,
          number of strands = 6,
          thick]
        {braid={s_4, s_5, s_4, s_3, s_2, s_1}};
      \end{tikzpicture}
    \end{center}
  \end{tabular}
\]

Note that the previous $\braid$ rule is a special case of $\longbraid$, with $k = 0$. Also, as before, the left-hand
sides of the relation are strictly larger than the right-hand sides, in terms of the lexicographic order on
$\List[\Fin[n]]$.

We define the relation $\longcox*$ to be the closure of $\longcox$, under reflexivity and (right-step extended)
transitivity.

\begin{definition}[$\longcox*$]
  \begin{align*}
    \reflr{\longcox}
     & : \forall w \to w \longcox* w                                                                               \\
    \transr{\longcox}
     & : \forall w_{1}, w_{2}, w_{3} \to  w_{1} \longcox w_{2} \to w_{2} \longcox* w_{3} \to w_{1} \longcox* w_{3} \\
  \end{align*}
\end{definition}

Despite the increased complexity of the generators, the rewriting system $(\List[\Fin[n]],\longcox*)$ has the properties
we desire. It satisfies confluence, that is, the Church-Rosser (diamond) property, and it is strongly normalising,
because it produces a unique irreducible normal form. Existence of the normal form is implied by the well-foundedness of
the relation -- informally, it does not contain any infinite decreasing sequences. We follow the terminology
of~\cite{krausCoherenceWellFoundednessTaming2020} to state our results formally.~\vc{check!}

\begin{proposition}
  \leavevmode
  \begin{enumerate}
    \item $\longcox$ is (locally) confluent. For every span $\coxspan{w_{1}}{w_{2}}{w_{3}}$, there is a matching
          extended cospan $\coxcospan*{w_{2}}{w_{3}}{w}$.
    \item $\longcox*$ is confluent. For every extended span $\coxspan*{w_{1}}{w_{2}}{w_{3}}$, there is a matching
          extended cospan $\coxcospan*{w_{2}}{w_{3}}{w}$.
    \item $\longcox*$ is well-founded. With $<$ the lexicographic ordering on $\List[\Fin[n]]$, and $w$ being
          $<$-accessible if every $v < w$ is $<$-accessible, we have that every $w$ is $<$-accesible.
    \item $\longcox*$ is strongly normalising. For every $w$, there exists a unique $v$ such that $w \longcox* v$.
  \end{enumerate}
\end{proposition}

The modified form of the Coxeter relations are unwieldy and difficult to prove properties about by induction. However,
we can use the following observation to be able to use the more standard $\cox*$ relation.~\todo{Check Huet's paper for
  this property.}

\begin{proposition}~\label{prop:coxlongcox}
  $\cox*$ and $\longcox*$ are equivalent in the following sense: for every $w$ and $v$, $w \cox* v$ iff there is a $u$
  such that $w \longcox* u$ and $v \longcox* u$.
\end{proposition}

By strong normalisation, we get a unique choice function $\normf : {\List[\Fin[n]]} \to {\List[\Fin[n]]}$ that produces
a normal form for terms of $\List[\Fin[n]]$. We state and prove a couple of important properties enjoyed by $\normf$.

\begin{proposition}
  \leavevmode
  \begin{enumerate}
    \item For all $l : \List[\Fin[n]]$, we have that $l \cox* \normf(l)$.
    \item $\normf$ is idempotent, that is, $\normf \comp \normf \htpy \normf$.
  \end{enumerate}
\end{proposition}

The type $\Sn$ is defined as the set-quotient of $\List[\Fin[n]]$ by $\cox*$,

\begin{definition}[$\Sn$]
  \(\Sn \defeq \quot{\List(\Fin[n])}{\cox*}\)
\end{definition}

Note that this relation $\cox*$ is not $\hProp$-valued, that is, $w \cox* v$ is not a proposition because reductions are
not unique. Because of this, the quotient $\Sn$ is not effective, that is, $\quotrel : w \cox* v \to q(w) \id q(v)$ is
not an equivalence. We could truncate the relation to change this, but then the codomain of $\normf$ also needs to be
truncated.

We could also define equivalence classes on $\List[\Fin[n]]$ to be those terms that have the same normal form. Using the
$\normf$ function, we could define a new relation $(w \approx v) \defeq (\normf(w) \id \normf(v))$ which is
$\hProp$-valued, and quotient $\List[\Fin[n]]$ by $\approx$. Using the properties of the rewriting system we proved, we
make a few observations.

\begin{proposition}
  \leavevmode
  \begin{enumerate}
    \item $\normf$ splits into a section-retraction pair, that is, we have ${\List[\Fin[n]]} \xrightarrow{s} \Sn[n]
            \xrightarrow{r} {\List[\Fin[n]]}$ such that $s \comp r \htpy \normf$ and $r \comp s \htpy \idfunc_{\Sn[n]}$.
    \item \(\im{\quotinc} \eqv \Sn \eqv \im{\normf} \).
  \end{enumerate}
\end{proposition}

Notice however, that a group presentation, as defined in~\cref{def:presentation}, requires the relation to be on the set
of words $A + A$, where the right copy corresponds to the set of formal inverses of the generators. The constructor
$\cancel$ specifies that the inverse of each element is again the same element, using which we can show that our
definition of $\Sn$ is equivalent to the definition of a presented group, by lifting the $\cox*$ relation.

\begin{proposition}
  \leavevmode
  \begin{enumerate}
    \item There is a group structure on $\Sn$, where the identity element is $\nil$, multiplication is given by list
          append, and inverse is given by list reversal.
    \item $\Sn$ is equivalent to the group presented by generators $\Fin[n] + \Fin[n]$ with the relations given by the
          normal closure of $\cox*$ extended to $\List(\Fin[n] + \Fin[n])$ along the codiagonal map $\nabla_{A} : A + A
            \to A$.
  \end{enumerate}
\end{proposition}

We set out to solve the word problem for $\Sn$. To decide if two words in $\List[\Fin[n]]$ are equal, we simply have to
compute their normal forms using $\normf$ and check if they're equal on the nose. If they do, they correspond to the
same permutation.

\subsection{Lehmer Codes}~\label{subsec:lehmer}

To prove the equivalence between $\Aut[\Fin[n]]$ and $\Sn[n]$, we will need to define functions back and forth between
the two types. The terms in $\Sn$ can be identified with equivalence classes of terms in $\List[\Fin[n]]$ with respect
to the Coxeter relation $\cox*$. The easiest way to define a function out of this presentation is to define it on the
representatives. We know that these are the unique normal forms in the set-quotient given by $\quotinc \comp \normf$,
but now we will describe what these representatives exactly look like, using an encoding called Lehmer
codes~\cite{lehmerTeachingCombinatorialTricks1960}.

There are many ways to represent permutations, e.g. inversions, or cycles, or matrices. Lehmer codes are known in
Combinatorial Analysis~\cite{bellmanCombinatorialAnalysis1960} where they are sometimes called "subexcedant sequences",
or "factoriadics", which give the factorial number system. They are a particularly convenient way of representing
permutations on a computer, partly because they are bitwise-optimal: for any $n : \Nat$, the type $\Lehmer[n]$ hass the cardinality $\fac{n}$, and has an easy to consttuct bijection with $\Aut[\Fin[n]]$. .

Formally, we define $\Lehmer[n]$ to be an $n+1$-element tuple, where the position $k \leq n$ stores an element of $\Fin[k]$. Since
the 0-th position is trivial, in practice, it is ignored, and the sequence starts at
1~\cite{duboisTestsProofsCustom2018,vajnovszkiNewEulerMahonian2011}.\todo{There are more examples - listed
  in~\cite{duboisTestsProofsCustom2018}}. We can then define $\Lehmer$ in two equivalent ways, by a simple recursion on
$\Nat$, or as a type family generated by two constructors.

\begin{definition}[$\Lehmer : \Nat \to \UU$]
  \begin{gather*}
    \begin{aligned}
      \Lehmer[\zero]   & \defeq \Fin[\suc[\zero]]                     \\
      \Lehmer[\suc[n]] & \defeq \Fin[\suc[\suc[n]]] \times \Lehmer[n]
    \end{aligned}
    \qquad
    \begin{aligned}
      \lzero & : \Lehmer[\zero]                                                     \\
      \lsuc  & : \forall n, r, (r \leq \suc[n]) \to \Lehmer[n] \to \Lehmer[\suc[n]]
    \end{aligned}
  \end{gather*}
\end{definition}

\todo{Explain why the two definitions are equivalent?}

For a permutation $\sigma : \Aut[\Fin[n]]$, for any element $i: \Fin[n]$, we can define the inversion count of $i$ as
the number of smaller elements appearing after it in the permutation.

\todo{typify}
\begin{definition}
  Given a permutation $\sigma : \Aut[\Fin[n]]$, the inversion count of $k: \Fin[n]$ is given by
  \[ |\Set{j < i | \sigma(j) > \sigma(i)}|. \]
\end{definition}

It turns out that from knowing just the inversion counts for all the elements, one can reconstruct the starting
permutation. Also, observe that the inversion count for element $i$ is guaranteed to be smaller than $i$, thus fitting
in the $i$-th place of a Lehmer code tuple. As an example, consider the following tabulated presentation of a
permutation of $\Fin[5]$.

\[
  \sigma =
  \begin{pmatrix}
    0      & 1      & 2      & 3      & 4      \\
    \el{2} & \el{1} & \el{4} & \el{0} & \el{3} \\
  \end{pmatrix}
\]

The inversion count for $\el{0}$ is 0 (because there are no smaller elements at all), for $\el{1}$ is 1 (because of
$\el{0}$ appearing after), for $\el{2}$ is 2 (because of $\el{0}$ and $\el{1}$), for $\el{3}$ is 0 (because it comes
last in the sequence), and for $\el{4}$ is 2 (because of $\el{3}$ and $\el{0}$). Thus, the Lehmer code for the permutation $\sigma$
is the 5-tuple $l = (0, 1, 2, 0, 2)$.

To decode the permutation back from this Lehmer code, we perform an algorithm similar to \emph{insertion sort}. The
element of the Lehmer code being currently processed is highlighted in the left column of the table below. Starting from
a sorted list, the element at index $k$ has to be given $l[k]$ inversions. Because of the the invariant that all the
elements before newly processed one are smaller than it, the proper number of inversions is created by simply shifting
the element $l[k]$ places left.

\begin{center}
  \begin{tabular}{l|r}
    (\highlight{{0}}, 1, 2, 0, 2) & $[\highlightAlt{\el{0}}, \el{1}, \el{2}, \el{3}, \el{4}]$ \\
    (0, \highlight{{1}}, 2, 0, 2) & $[\highlightAlt{\el{1}}, \el{0}, \el{2}, \el{3}, \el{4}]$ \\
    (0, 1, \highlight{{2}}, 0, 2) & $[\highlightAlt{\el{2}}, \el{1}, \el{0}, \el{3}, \el{4}]$ \\
    (0, 1, 2, \highlight{{0}}, 2) & $[\el{2}, \el{1}, \el{0}, \highlightAlt{\el{3}}, \el{4}]$ \\
    (0, 1, 2, 0, \highlight{{2}}) & $[\el{2}, \el{1}, \highlightAlt{\el{4}}, \el{0}, \el{3}]$ \\
  \end{tabular}
\end{center}

Writing formally, to turn a code into a permutation written in the Coxeter presentation, we define a function
$\immersion$. As described above, the number $r$ at position $k$ in the tuple describes how many inversions the element
$\el{k}$ has. Thus, we need to perform $r$ many adjacent transpositions to get to the desired position, which is given
by $(\suc[n] - r) \downf r$.

\begin{definition}[$\immersion : (n : \Nat) \to {\Lehmer[n]} \to {\List[\Fin[\suc[n]]]}$]
  \begin{align*}
    \immersion(\zero, \zero)    & \defeq \nil                                              \\
    \immersion(\suc[n], (r, l)) & \defeq \immersion(n, l) \append ((\suc[n] - r) \downf r)
  \end{align*}
\end{definition}

As an example, let us look at the code $c = (4, 3, 2, 1, 0)$. The list $\immersion(c)$ is then going to be $[0, 1, 0, 2,
      1, 0, 3, 2, 1, 0, 4, 3, 2, 1, 0]$. It is a concatenation of a sequence of decreasing lists. Where could a reduction
happen? First, it can't happen inside any of the decreasing components: $\longcancel$ requires repeating elements,
$\longswap$ acts when a smaller number precedes a larger one, and $\longbraid$ has a non-monotone sequence on the left.
This leaves the case of a reduction happening on a fragment that borders two subsequences. Again, $\longcancel$ requires
two equal consecutive numbers, which have to be the last one in some decreasing sequence and the first one in the next
one. But the first number in a sequence is always larger than every number in the sequence before it - which also shows
why $\longswap$ cannot happen. The remaining case of $\longbraid$ is proven on similar grounds, since it requires the
number appearing after the decreasing sequence to be equal to the first one in the sequence.

Using this idea, we can show that the function $\immersion$ gives an equivalence betweeen $\Lehmer[n]$ and
$\im{\normf}$.

\begin{proposition}
  \leavevmode
  \begin{enumerate}
    \item For any Lehmer code $c$, $\immersion(c)$ is a normal form with resepct to $\longcox*$, that is, $\immersion(c)$ is
          in $\im{\normf}$.
    \item Any element of $\im{\normf}$ can be constructed from a unique Lehmer code by $\immersion$, that is, the fibers
          of $\immersion: \Lehmer[n] \to {\im{\normf}}$ are contractible.
  \end{enumerate}
  Therefore, there is an equivalence between $\Lehmer[n]$ and $\im{\normf}$.
\end{proposition}

We also established an equivalence between $\im{\normf}$ and $\Sn$, which gives the following.

\begin{proposition}~\label{prop:sn-im-lehmer-equiv}
  For all $n : \Nat$, \( \Sn \eqv \im{\normf} \eqv \Lehmer[n] \).
\end{proposition}

\subsection{Running Lehmer codes}

Finally, it is time to complete our goal of characterising the permutation groups. Having produced a Lehmer code by
normalising words in $\Sn$, we need to run it to produce a concrete bijection of finite sets, and, given a bijection
between finite sets, we need to encode it as a Lehmer code. We will prove that these maps construct an equivalence
between the types $\Lehmer[n]$ and $\Aut[\Fin[\suc[n]]]$.

To do so, we need to construct some equivalences by counting the elements of $\Fin[n]$ using its decidable equality.
First, we define a helper type family $\FinExcept{n} : \Fin[n] \to \UU$ which picks out all elements in $\Fin[n]$ except
the one in the argument. Note that $\FinExcept{n}[i]$ for $i : \Fin[n]$ is a subtype of $\Fin[n]$ and is hence an
$\hSet$.

\begin{definition}
  \( \FinExcept{n}[i] \defeq \dsum{j : \Fin[n]}{i \neq j} \).
\end{definition}

We state and prove a few auxiliary lemmas about how $\FinExcept{n}$ interacts with $\Fin$.

\begin{proposition}~\label{prop:fin-finexcept}
  \leavevmode
  \begin{enumerate}
    % \item For any $k : \Fin[n]$, $\unit \sqcup \FinExcept{n}[k] \eqv \Fin[n]$. \label{prop:fin-finexcept-1}
    \item For any $k : \Fin[\suc[n]]$, $\FinExcept{\suc[n]}[k] \eqv \Fin[n]$. \label{prop:fin-finexcept-2}
    \item For any $n : \Nat$, \( \Aut[\Fin[\suc[n]]] \eqv \dsum{k : \Fin[\suc[n]]}{\FinExcept{\suc[n]}[n] \eqv
            \FinExcept{\suc[n]}[n - k]} \). \label{prop:fin-finexcept-3}
  \end{enumerate}
\end{proposition}

\begin{proof}
  The first and second propositions follow from simply constructing the bijections using the decidable equality of
  $\Fin[n]$, and making sure to punch-in and punch-out the element $k$ at the right place.

  The third proposition performs some combinatorial tricks. On the left, we have the type of automorphisms of
  $\Fin[\suc[n]]$. Assume a particular $\sigma : \Fin[\suc[n]] \xrightarrow{\sim} \Fin[\suc[n]]$. Pick $k$ to be the
  inversion count of $n$, the largest element in $\Fin[\suc[n]]$. Then, the image of $n$ under $\phi$ has to be $n - k$,
  since all other elements in the set are smaller. Removing those two from the domain and codomain of $\phi$, the rest
  of the elements are fixed by $\sigma$, so we compute the bijection between the rest of the elements.

  For the other direction, if we are given a $k$ and a bijection $\pi$ between $\FinExcept{\suc[n]}[n]$ and
  $\FinExcept{\suc[n]}[n - k]$, we can extend $\pi$ to $\sigma : \Fin[\suc[n]] \eqv \Fin[\suc[n]]$ by inserting the
  element $n$ at the position $n - k$, resulting in the element $n$ having inversion count $k$.
\end{proof}

Using these facts, we can now prove the main result of this section.

\begin{proposition}~\label{prop:lehmer-aut-equiv}
  For all $n:\Nat$, \( \Lehmer[n] \eqv \Aut[\Fin[\suc[n]]] \).
\end{proposition}

\begin{proof}
  For $n = \zero$, note that $\Lehmer[\zero]$ is contractible, and so is $\Aut[\Fin[\suc[\zero]]]$. For $n = \suc[m]$,
  we compute a chain of equivalences.
  \begin{gather*}
    \arraycolsep=0.5em\def\arraystretch{1.5}
    \begin{array}{rl}
           & \Lehmer[\zero]          \\
      \eqv & \unit                   \\
      \eqv & \Aut[\Fin[\suc[\zero]]] \\
    \end{array}
    \qquad\qquad
    \begin{array}{rlr}
           & \Lehmer[\suc[m]]                                                                                   &                                                                 \\
      \eqv & \Fin[\suc[\suc[m]]] \times \Lehmer[m]                                                              & \text{by definition}                                            \\
      \eqv & \Fin[\suc[\suc[m]]] \times \Aut[\Fin[\suc[m]]]                                                     & \text{induction hypothesis}                                     \\
      \eqv & \dsum{k : \Fin[\suc[\suc[m]]]}{\Fin[\suc[m]] \eqv \Fin[\suc[m]]}                                   & \text{$\Sigma$ over a constant family}                          \\
      \eqv & \dsum{k : \Fin[\suc[\suc[m]]]}{\FinExcept{\suc[\suc[m]]}[m] \eqv \Fin[\suc[m]]}                    & \text{by~\cref{prop:fin-finexcept}~\cref{prop:fin-finexcept-2}} \\
      \eqv & \dsum{k : \Fin[\suc[\suc[m]]]}{\FinExcept{\suc[\suc[m]]}[m] \eqv \FinExcept{\suc[\suc[m]]}[m - k]} & \text{by~\cref{prop:fin-finexcept}~\cref{prop:fin-finexcept-2}} \\
      \eqv & \Aut[\Fin[\suc[\suc[m]]]]                                                                          & \text{by~\cref{prop:fin-finexcept}~\cref{prop:fin-finexcept-3}} \\
    \end{array}
  \end{gather*}
\end{proof}

By composing~\cref{prop:lehmer-aut-equiv} and~\cref{prop:sn-im-lehmer-equiv}, we obtain the final equivalence.

\begin{corollary}
  For all $n : \Nat$,
  \(
  \Sn \eqv \Lehmer[n] \eqv \Aut[\Fin[\suc[n]]]
  \).
\end{corollary}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% fill-column: 120
%%% End:
